# tokenize dataset using tiktoken and save the tokens and merges
    # import tiktoken and train it on the dataset
    # from the generated tokens, 
# using these tokens and merges, create a config using huggingface tokenizers